| ID | Category | Requirement Description | Implementation Notes |
| --- | --- | --- | --- |
| **REQ-TOOL-01** | **Tooling** | **Define "Vector Search" Tool**<br>

<br>Wrap `db.search_vectors` into a standalone function exposed to the LLM. | **Input:** `query_string` (str).<br>

<br>**Output:** Formatted string of top chunks.<br>

<br>**Logic:** Generates embedding internally, then calls DB. |
| **REQ-TOOL-02** | **Tooling** | **Define "Graph Search" Tool**<br>

<br>Wrap `db.search_nodes_by_name` and `db.get_chunks_by_concepts` into a tool. | **Input:** `concept_names` (List[str]).<br>

<br>**Output:** List of related concepts and connected chunks.<br>

<br>**Logic:** Uses 1-hop neighbor logic from current `app.py`. |
| **REQ-TOOL-03** | **Tooling** | **Define "Project Summary" Tool**<br>

<br>Expose `db.get_all_file_summaries` as a tool. | **Input:** None (or project_id context).<br>

<br>**Output:** Concatenated summaries of all files.<br>

<br>**Use Case:** "What is this project about?" |
| **REQ-AGENT-01** | **AI Engine** | **Implement Tool-Calling Loop**<br>

<br>Update `AIEngine` to support a "think-act-observe" loop (or native function calling if using Llama 3.1+). | **Loop:**<br>

<br>1. Send User Query + Tool Defs.<br>

<br>2. Check if LLM wants to call a tool.<br>

<br>3. Execute tool Python code.<br>

<br>4. Feed result back to LLM.<br>

<br>5. Repeat until Final Answer. |
| **REQ-AGENT-02** | **AI Engine** | **System Prompt Engineering**<br>

<br>Create a system prompt that clearly defines *when* to use which tool. | *Example:* "Use `vector_search` for specific code questions. Use `graph_search` for high-level concept connections. Use `project_summary` for broad overviews." |
| **REQ-UI-01** | **App Logic** | **Refactor Chat Flow**<br>

<br>Replace the `determine_intent` -> `if/else` block in `app.py` with a single `agent.run(prompt)` call. | The `app.py` becomes much cleaner. It no longer manages retrieval logic; it just initializes the agent and displays the stream. |
| **REQ-UI-02** | **UX** | **Tool Execution Visibility**<br>

<br>The UI should show "searching..." or "checking graph..." indicators when the agent uses a tool. | Streamlit `st.status` or `st.spinner` can be updated via a callback from inside the agent loop. |
